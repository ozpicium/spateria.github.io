
<!DOCTYPE HTML>
<html lang="en">
  <head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
    
    </script>

    <script async defer src="https://buttons.github.io/buttons.js">
    </script>

	
  <title>Shubham Pateria</title>
  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <meta name="author" content="Shubham Pateria">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">

	
</head>

  <body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr style="padding:0px">
          <td style="padding:0px">
    	      
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <td style="padding:0%;width:70%;vertical-align:middle">
                <p style="font-size:250%;font-family:verdana"> <name> Shubham Pateria </name> </p>
                <p> 
                  I am a Research Scientist at <a href="https://www.smu.edu.sg/">Singapore Management University (SMU), Singapore</a> in the <a href="https://sites.google.com/smu.edu.sg/cognitiveandneuralcomputing/home?authuser=0">Neural and Cognitive Computing Group</a>, since April, 2022. My work is primarily focused on multi-agent reinforcement learning and <a href="https://en.wikipedia.org/wiki/Federated_learning">federated learning</a>. 
                </p>
                <p>
                  At SMU, I am a key contributor to the <a href="https://sites.google.com/smu.edu.sg/cognitiveandneuralcomputing/projects#h.vj0pjwaa76rz">Scalable and Interpretable iCGF</a> project funded by <a href="https://www.dso.org.sg/">DSO National Laboaratories</a> and <a href="https://sites.google.com/smu.edu.sg/cognitiveandneuralcomputing/projects#h.1jb4lx4ixurb">Trustworthy Federated Ubiquitous Learning (TrustFUL)</a> project funded by <a href="https://aisingapore.org/">AISG</a>. Prior to this, I was a part of <a href="">Entrepreneur First</a>, Singapore startup incubator from which I briefly worked on my own mental health technology startup before shutting it down in early 2022.
                </p>
                
                <p>
                  Previously, I worked as a Senior Software Engineer at <a href="https://research.samsung.com/sri-b">Samsung Research India - Bangalore</a> on display driver software and innovative research on smartphone and smarthome system optimization. 
                </p>
                <p style="text-align:center">
                  <a href="mailto:shubhamp@smu.edu.sg">Email</a> &nbsp;/&nbsp;
                  <a href="data/ShubhamPateria_CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=PuJ5C_QAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/shubham-pateria-2091/">Linkedin</a> &nbsp;/&nbsp;
                  <a href="https://github.com/spateria/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/shubhamp.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/shubhamp.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
	
	<p>
	<p>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
	      <tbody>
               <p style="font-size:150%;font-family:verdana"> <name> <b>Education</b> </name> </p>
	       <p>
		       I received my <b>Doctor of Philosophy (Ph.D.)</b> degree in Computer Science from <a href="https://www.ntu.edu.sg/">Nanyang Technological University (NTU)</a>, Singapore in 2021. I was supervised by by <a href="https://sites.google.com/smu.edu.sg/ahtan/home">Prof. Ah-Hwee Tan</a> and <a href="https://scholar.google.com.sg/citations?user=Tj-KsfQAAAAJ&hl=en">Assoc. Prof. Chai Quek</a>. My area of specialization was reinfocement learning and thesis was on <a href="">Methods for autonomously decomposing and performing long-horizon sequential decision tasks</a>.

		       Prior to that, I received <b>Bachelor of Technology (B.Tech.)</b> degree in Electronics and Communications Engineering form <a href="https://nitdgp.ac.in/">National Institute of Technology (NIT), Durgapur</a>, India in 2013.
	       </p>
	    
        </tbody></table>
		
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
               <p style="font-size:150%;font-family:verdana"> <name> <b>Interests</b> </name> </p>
		<p> 
	     <ul class="b">
	      <li> Artificial Intelligence and Machine Learning. </li>
	      <li> Reinforcement Learning, Planning, and Control. </li>
	      <li> Federated Learning, Data Privacy.</li>
	      <li> Data Science. </li>
	     </p>
		     
	     </ul>
            </td>
        </tbody></table>
	  
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
	<p style="font-size:150%;font-family:verdana"> <name> <b>Research Projects and Publications</b> </name> </p>
    
      <tr onmouseout="hisoma_stop()" onmouseover="hisoma_start()">
	    <td style="padding:10px;width:25%;vertical-align:middle">
	      <div class="one">
		<img src='images/hisoma.png' width="210">
	      </div>
	    </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://sites.google.com/smu.edu.sg/cognitiveandneuralcomputing/projects#h.vj0pjwaa76rz"> <b>Hierarchical Multi-agent Control using Deep Reinforcement Learning and Self-organizing Neural Networks</b> </a>
		</p>
			Minghong Geng, <u><b>Shubham Pateria</b></u>, Budhitama Subagdja, Ah-Hwee Tan. <br>
		<p>
			[<b>Confidential</b>] <i>Licensed to DSO National Laboratories, Singapore in 2023.</i>
		<p>
			A hierarchical multi-agent reinforcement learning system combining self-organizing and deep neural networks, for simulated defense research technology licensed to DSO National Laboratories. The codes and documentation related to this research is currently confidential.
		</p>
		 </td>			
	</tr>

	<tr onmouseout="explainART_stop()" onmouseover="explainART_start()">
	    <td style="padding:10px;width:25%;vertical-align:middle">
	      <div class="one">
		<img src='images/explainART.png' width="210">
	      </div>
	    </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://dl.acm.org/doi/abs/10.5555/3545946.3598922"> <b>Towards Explaining Sequences of Actions in Multi-Agent Deep Reinforcement Learning Models</b> </a>
		</p>
			Khaing Phyo Wai, Minghong Geng, Budhitama Subagdja, <u><b>Shubham Pateria</b></u>, Ah-Hwee Tan. <br>
		<p> 
			[<b>AAMAS 2023</b>] <i>In the 2023 International Conference on Autonomous Agents and Multiagent Systems.</i> <br>
		<p> 	
			[<a href="data/explainART_paper.pdf"> poster</a>]  
		</p> 
		<p>
			A novel approach to explain Multi-agent Deep Reinforcement Learning (MADRL) by transforming sequences of action events performed by agents into high-level abstract strategies using a spatio-temporal neural network model.
		</p>
		 </td>			
	</tr>

	<tr onmouseout="lsgvp_stop()" onmouseover="lsgvp_start()">
	    <td style="padding:10px;width:25%;vertical-align:middle">
	      <div class="one">
		<img src='images/lsgvp.png' width="210">
	      </div>
	    </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://ieeexplore.ieee.org/abstract/document/10040536"> <b>LSGVP: Value-Based Subgoal Discovery and Path Planning for Reaching Long-Horizon Goals</b> </a>
		</p>
			<u><b>Shubham Pateria</b></u>, Budhitama Subagdja, Ah-Hwee Tan, Chai Quek. <br>
		<p> 
			[<b>IEEE TNNLS 2023</b>] <i>In IEEE Transactions on Neural Networks and Learning Systems, doi: 10.1109/TNNLS.2023.3240004; (Impact Factor: 14.255).</i> <br>
		<p> 	
			[<a href="data/lsgvp_paper.pdf"> paper</a>]  
		</p> 
		<p>
			LSGVP is a subgoal-graph planning method for goal-based navigation and simulated robot control. It uses a subgoal discovery heuristic that is based on a cumulative reward (value) measure and yields sparse subgoals, including those lying on the higher cumulative reward paths. Moreover, LSGVP guides the agent to automatically prune the learned subgoal graph to remove the erroneous edges. The combination of these novel features helps the LSGVP agent to achieve higher cumulative positive rewards than other subgoal sampling or discovery heuristics, as well as higher goal-reaching success rates than other state-of-the-art subgoal graph-based planning methods.
		</p>
		 </td>			
	</tr>

	<tr onmouseout="lidoss_stop()" onmouseover="lidoss_start()">
	    <td style="padding:10px;width:25%;vertical-align:middle">
	      <div class="one">
		<img src='images/lidoss.png' width="210">
	      </div>
	    </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://ieeexplore.ieee.org/abstract/document/9462536"> <b>LIDOSS: End-to-End Hierarchical Reinforcement Learning With Integrated Subgoal Discovery</b> </a>
		</p>
			<u><b>Shubham Pateria</b></u>, Budhitama Subagdja, Ah-Hwee Tan, Chai Quek. <br>
		<p> 
			[<b>IEEE TNNLS 2022</b>] <i>In IEEE Transactions on Neural Networks and Learning Systems, vol. 33, no. 12, pp. 7778-7790, Dec. 2022, doi: 10.1109/TNNLS.2021.3087733; (Impact Factor: 14.255).</i> <br>
		<p> 	
			[<a href="data/lidoss_paper.pdf"> paper</a>]  
		</p> 
		<p>
			LIDOSS is an end-to-end Hierarchical Reinforcement Learning (HRL) method for goal-based navigation and simulated robot control. It introduces a subgoal discovery heuristic that narrows down the search space for the higher-level policy by focusing on subgoals that are more likely to occur in state-transitions leading to the goal. Evaluated against a state-of-the-art HRL method called Hierarchical Actor Critic (HAC), LIDOSS demonstrates improved goal achievement rates across various continuous control tasks.
		</p>
		 </td>			
	</tr>

	<tr onmouseout="hrlsurvey_stop()" onmouseover="hrlsurvey_start()">
	    <td style="padding:10px;width:25%;vertical-align:middle">
	      <div class="one">
		<img src='images/hrlsurvey.png' width="210">
	      </div>
	    </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://dl.acm.org/doi/abs/10.1145/3453160"> <b>Hierarchical Reinforcement Learning: A Comprehensive Survey</b> </a>
		</p>
			<u><b>Shubham Pateria</b></u>, Budhitama Subagdja, Ah-Hwee Tan, Chai Quek. <br>
		<p> 
			[<b>ACM CSUR 2022</b>] <i>In ACM Computing Surveys 54, 5, Article 109 (June 2022), 35 pages. https://doi.org/10.1145/3453160; (Impact Factor: 14.324).</i> <br>
		<p> 	
			[<a href="data/hrlsurvey_paper.pdf"> paper</a>]  
		</p> 
		<p>
			We provide a survey of both foundational as well as recent Hierarchical Reinforcement Learning (HRL) approaches concerning the challenges of learning hierarchical policies, subtask discovery, transfer learning, and multi-agent learning using HRL. The survey is presented according to a novel taxonomy of the approaches. Based on the survey, a set of important open problems is proposed to motivate the future research in HRL.
		</p>
		 </td>			
	</tr>

	<tr onmouseout="hrlsurvey_stop()" onmouseover="hrlsurvey_start()">
	    <td style="padding:10px;width:25%;vertical-align:middle">
	      <div class="one">
		<img src='images/lidossold.png' width="210">
	      </div>
	    </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://dl.acm.org/doi/abs/10.5555/3398761.3399042"> <b>Hierarchical Reinforcement Learning with Integrated Discovery of Salient Subgoals</b> </a>
		</p>
			<u><b>Shubham Pateria</b></u>, Budhitama Subagdja, Ah-Hwee Tan. <br>
		<p> 
			[<b>AAMAS 2020</b>] <i>In the 19th International Conference on Autonomous Agents and MultiAgent Systems.</i> <br>
		<p> 	
			[<a href="data/lidossold_paper.pdf"> paper</a>]  
		</p> 
		 </td>			
	</tr>
	      
	<tr onmouseout="isemo_stop()" onmouseover="isemo_start()">
	    <td style="padding:10px;width:25%;vertical-align:middle">
	      <div class="one">
		<img src='images/isemo.png' width="210">
	      </div>
	    </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://ieeexplore.ieee.org/abstract/document/9002777"> <b>ISEMO: Multi-agent Reinforcement Learning in Spatial Domain Tasks using Inter Subtask Empowerment Rewards</b> </a>
		</p>
			<u><b>Shubham Pateria</b></u>, Budhitama Subagdja, Ah-Hwee Tan. <br>
		<p> 
			[<b>IEEE SSCI 2019</b>] <i>In IEEE Symposium Series on Computational Intelligence (SSCI), Xiamen, China, 2019, pp. 86-93, doi: 10.1109/SSCI44817.2019.9002777.</i> <br>
		<p> 	
			[<a href="data/isemo_paper.pdf"> paper</a>] 
			[<a href="https://github.com/spateria/ISEMO/tree/master"> codes</a>]
		</p> 
		<p>
			ISEMO is a Multi-agent Hierarchical Reinforcement Learning (MAHRL) that uses an Inter-Subtask Empowerment Reward (ISER) to facilitate cooperation among agents in complex tasks, where some agents are essential for reaching rewarding states while others play supporting roles. ISER complements task rewards, enhancing inter-agent coordination, and ISEMO includes an options model to learn subtask termination functions, improving flexibility compared to hand-crafted conditions. Experiments demonstrate that ISEMO effectively learns subtask policies and terminations, outperforming standard MAHRL in a spatial Search and Rescue scenario.
		</p>
		 </td>			
	</tr>
	      
    </tbody></table>

    <p>
    <p>
	
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
               <p style="font-size:150%;font-family:verdana"> <name> <b>Patents</b> </name> </p>
		<p> 
	     <ul class="b">
		<li> <a href="https://iprsearch.ipindia.gov.in/PublicSearch/"><b>METHOD AND SYSTEM FOR OPTIMIZING POWER CONSUMPTION IN A DISPLAY DEVICE</b> </a> 
			[<a href="https://iprsearch.ipindia.gov.in/PublicSearch/"> patent</a>]
		</li>
			 Ashish Kumar SINGH, <u><b>Shubham PATERIA</b></u>, Kumar KATRAGADDA, Krishna Kishor JHA, Vaisakh Punnekkattu Chiryal Sudheesh BABU. <i>Samsung R&D India-Bangalore.</i> <br>
		[<b>IN Patent</b>] <i>  India Patent 201741038214, 2019.  </i><br> </p>

		<li> <a href="https://iprsearch.ipindia.gov.in/PublicSearch/"><b>METHOD AND SYSTEM FOR AN EYE SENSATION PREDICTION BASED DISPLAY ENHANCEMENT</b> </a> 
			[<a href="https://iprsearch.ipindia.gov.in/PublicSearch/"> patent</a>]
		</li>
			 Krishna Kishor JHA, Ashish Kumar SINGH, Deepthy RAVI, <b><u>Shubam PATERIA</u></b>, Vaisakh Punnekkattu Chirayil SUDHEESH BABU, Mahammadrafi Raimansab MANIYAR. <i>Samsung R&D India-Bangalore.</i> <br>
		 [<b>IN Patent</b>] <i>India Patent 201741008468, 2019.  </i><br> </p>

		
		 </td>
        </tbody></table>
	  
    <p>
    <p>
	
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
               <p style="font-size:150%;font-family:verdana"> <name> <b>Other Works</b> </name> </p>
		<p> 
	     <ul class="b">
		<li> <a href="https://ieeexplore.ieee.org/abstract/document/7154732"><b>Power efficient, bandwidth optimized and fault tolerant sensor management for IOT in Smart Home</b> </a> 
		</li>
			 Pradulla Choubey, <u><b>Shubham Pateria</b></u>, Aseem Saxena, Vaisakh PCSB, Krishna Kishor Jha, Sharana Basaiah PM. <i>Samsung R&D India-Bangalore.</i> <br>
		  [<b>IEEE IACC</b>] <i>2015 IEEE International Advance Computing Conference  </i><br> </p>

		<li> <a href="https://aclanthology.org/C16-1248/"><b>Aspect Based Sentiment Analysis using Sentiment Flow with Local and Non-local Neighbor Information</b> </a> 
			[<a href="https://aclanthology.org/C16-1248.pdf"> paper</a>] 
		</li>
			 <u><b>Shubham Pateria</b></u> <br>
		  [<b>COLING</b>] <i>The 26th International Conference on Computational Linguistics, 2016.  </i><br></p>

		<li> <a href="https://github.com/spateria/Sign-Language-Interpreter"><b>Character-level Sign Language Interpretation from Hand-gestures using Recurrent Convolutional Neural Networks</b> </a> 
			[<a href="https://github.com/spateria/Sign-Language-Interpreter"> Project</a>] 
		</li>
			 <u><b>Shubham Pateria</b></u>, Abhay MS Aradhya, Andri Ashfahani, Mohamed Ragab. <i>NTU, Singapore.</i> <br>
		  We developed a Convolutional LSTM model that takes a sequence of hand gestures as input and produces the corresponding word as output. The gesture data was obtained from Sign Language MNIST on Kaggle.
Our Conv LSTM model achieved a word prediction (test) accuracy of 96.8% compared to the 64.5% accuracy achieved only with character prediction CNN (without hidden state recurrence).
On top of this, we also developed a Sequence-to-Sequence LSTM which was trained on the pairs of (incorrectly spelled, correctly spelled) words. This was used as a post-processor on the output of Conv LSTM. This improved the test accuracy to 99.1%.  <br></p>

		 </td>
        </tbody></table>

	
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
               <p style="font-size:150%;font-family:verdana"> <name> <b>Teaching Experience</b> </name> </p>
		<p> 
	     <ul class="b">
              <p> <b> Teaching Assistant</b> </p>
	      <li> CZ2001: Algorithms, Semester 2, 2018, NTU, Singapore. </li>
	      <li> CZ3003: Software System Analysis and Design, Semester 1, 2019, NTU, Singapore. </li>
	      <li> CZ2001: Algorithms, Semester 2, 2019.</li>
	      <li> CZ1015: Introduction to Data Science, Semester 1, 2020, NTU, Singapore. </li>
	      <li> CZ3004: Multidisciplinary Design Project (MDP), Semester 2, 2020, NTU, Singapore. </li>
	     </p>
		     
	     </ul>
            </td>
        </tbody></table>
	<p>
	<p>
	 <!--           CopyRight-->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
 		<p style="text-align:right;">Modified from <a href="https://jonbarron.info/">Jon Barron</a></p>
                </tbody>
            </table>
	  
  </body>
</html>
